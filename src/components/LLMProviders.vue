<template>
  <div class="q-gutter-md llm-providers">
    <div class="column q-gutter-sm items-center">
      <TyMarkdown
        class="q-pb-md"
        src="
## Welcome to Taskyon!
        
You will need an API key for an OpenAI-compatible AI service. There are many options available for this. 
It is even possible to run your own inference service on a server.
"
      />
      <div class="row">
        <q-btn
          flat
          no-caps
          label="Use free Taskyon service (low quality)"
          to="/"
          @click="initFreeMode"
        ></q-btn>
        <InfoDialog>
          Pressing this button will add an API key which provides free API
          access to https://taskyon.space API for testing purposes &
          development.
        </InfoDialog>
      </div>
      <div class="col-auto text-italic">or</div>
    </div>
    <q-expansion-item
      label="Add API keys for AI services below:"
      class="transparent"
    >
      <q-card flat bordered>
        <q-card-section>
          You can specify connection settings (api keys etc...) for OpenAI
          compatible LLM Apis here. You can setup your own OpenAI-compatible
          server and connect to it or use other services:
        </q-card-section>

        <q-card-section class="q-gutter-md">
          <div class="row items-center">
            <div class="q-pr-md">
              Select which API to use. At least one API key needs to be
              specified below.
            </div>
            <ApiSelect v-model="state.llmSettings.selectedApi" />
          </div>
          <div>
            Activate API by specifying an API key (taskyon API keys can be
            generated by a registered user here:
            <a
              href="https://taskyon.space/account"
              target="_blank"
              rel="noopener noreferrer"
              >Taskyon Account</a
            >
            ):
          </div>
          <div>
            <SecretInput
              v-for="apiName of Object.keys(state.llmSettings.llmApis)"
              :key="apiName"
              placeholder="Add API key here!"
              filled
              :model-value="state.keys[apiName] || ''"
              :label="`${apiName} API key`"
              @update:model-value="(value) => (state.keys[apiName] = value)"
            >
            </SecretInput>
          </div>
        </q-card-section>
        <q-expansion-item
          v-if="expertModeOn"
          class="q-pa-sm"
          dense
          label="Edit Apis"
          :icon="matEdit"
        >
          <TyMarkdown
            src="Here, we can add new, custom APIs to taskyon that we can connect to
it is possible to add your own LLM Inference Server to connect
to your own AI this way. E.g. using these methods: 

- https://huggingface.co/blog/tgi-messages-api
- https://github.com/bentoml/OpenLLM

or with an llm proxy such as this one:  https://github.com/BerriAI/liteLLM-proxy
"
          />
          <JsonInput v-model="state.llmSettings.llmApis" />
        </q-expansion-item>
      </q-card>
      <div class="row q-py-md">
        <q-btn
          class="col"
          label="Go to Taskyon.space to retrieve an API key."
          outline
          no-caps
          icon="svguse:/taskyon_mono_opt.svg#taskyon"
          href="https://taskyon.space/account"
          target="_blank"
        />
        <InfoDialog
          info-text="
  https://taskyon.space is the official webpage of taskyon. You can
  retrieve API keys after logging in to your account.

  - Easily integrate taskyon into your webpage!
  - Access to more free models from a large selection of AI providers:

    Anthropic, OpenAI/ChatGPT, Google, Mistral, Meta, Huggingface and
    many more!
  "
        />
      </div>
      <OpenRouterPKCE class="q-py-md" />
      <q-expansion-item label="Retrieve Keys from other AI services">
        <q-item-label header>
          Manually configure & retrieve API keys (Setup a local,
          privacy-presevering server, a custom LLM AI server in your company
          etc...) Everything with an OpenAI compatible API will work:
        </q-item-label>
        <div class="row q-gutter-xs">
          <div class="col">
            <q-btn
              class="col"
              label="Use LLM inference using Huggingface Message API"
              outline
              no-caps
              href="https://huggingface.co/docs/text-generation-inference/en/messages_api"
              target="_blank"
            />
            <InfoDialog
              info-text="Huggingfaces message API https://huggingface.co/docs/text-generation-inference/en/messages_api is fully OpenAI compatible."
            />
          </div>
          <div class="col">
            <q-btn
              class="col"
              label="Go to OpenAI to retrieve an API key from OpenAI (not recommended)"
              outline
              no-caps
              href="https://platform.openai.com/account/api-keys"
              target="_blank"
            />
            <InfoDialog
              info-text="You can also get an API key from https://platform.openai.com/account/api-keys and manually 
insert into the settings below."
            />
          </div>
          <div class="col">
            <q-btn
              label="Access keys via OpenRouter Dashboard (not recommended)"
              outline
              no-caps
              href="https://openrouter.ai/keys"
              target="_blank"
            />
            <InfoDialog
              info-text="Get an API key from https://www.openrouter.ai and use it for inference tasks"
            />
          </div>
        </div>
      </q-expansion-item>
    </q-expansion-item>
  </div>
</template>

<script setup lang="ts">
import { useTaskyonStore } from 'stores/taskyonState';
import OpenRouterPKCE from './OpenRouterPKCE.vue';
import JsonInput from './JsonInput.vue';
import TyMarkdown from './tyMarkdown.vue';
import SecretInput from './SecretInput.vue';
import { matEdit } from '@quasar/extras/material-icons';
import ApiSelect from './ApiSelect.vue';
import InfoDialog from './InfoDialog.vue';
import { isTaskyonKey } from 'src/modules/taskyon/crypto';

const state = useTaskyonStore();

const expertModeOn = defineModel<boolean>('expertModeOn', { default: false });

function initFreeMode() {
  state.llmSettings.selectedApi = 'taskyon';
  state.keys['taskyon'] = taskyonConfiguration.taskyon_public_free_key;
  const pubKey = isTaskyonKey(
    taskyonConfiguration.taskyon_public_free_key,
    false,
  );
  if (pubKey?.model) {
    state.llmSettings.llmApis['taskyon']!.selectedModel = pubKey.model[0];
  }
}
</script>
